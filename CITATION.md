cff-version: 1.2.0
message: "If you use this software, please cite it as below."
title: "HB-Eval: Behavioral Certification for Agentic AI"
version: 0.1.0
date-released: 2026-02-05
url: "https://anonymous.4open.science/r/hb-eval-XXXX"
repository-code: "https://anonymous.4open.science/r/hb-eval-XXXX"
license: Apache-2.0
type: software

authors:
  - family-names: "Anonymous"
    given-names: "Authors"
    affiliation: "Anonymous Institution"

preferred-citation:
  type: conference-paper
  title: "HB-Eval: Toward Verifiable Behavioral Certification for Agentic AI"
  authors:
    - family-names: "Anonymous"
      given-names: "Authors"
  collection-title: "VerifAI Workshop @ ICLR 2026"
  year: 2026
  conference:
    name: "VerifAI: AI Verification in the Wild"
  url: "https://verifai-workshop.github.io/"
  
keywords:
  - "ai-safety"
  - "agent-evaluation"
  - "behavioral-certification"
  - "reinforcement-learning"
  - "verification"
  - "reliability-testing"
  - "stress-testing"
  
abstract: |
  Current evaluation paradigms for agentic AI systems conflate capability 
  with reliability, measuring what agents can achieve under ideal conditions 
  while systematically obscuring behavioral deficits emerging under deployment 
  stress. We propose HB-Eval as a conceptual framework distinguishing these 
  orthogonal dimensions through four integrated architectural layers. Initial 
  empirical validation reveals reliability gaps reaching 43 percentage points, 
  demonstrating that traditional metrics dramatically overestimate deployment 
  readiness. We contribute a fundamental negative result showing that 
  reinforcement learning from verification signals induces systematic agent 
  withdrawalâ€”a pathology we prove constitutes Nash equilibrium in multi-agent 
  settings.
